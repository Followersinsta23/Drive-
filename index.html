<!DOCTYPE html><html>
<head>
  <title>VisionGuard 5.0 – Real-Time Object Detection</title>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.13.0"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd@2.2.2/dist/coco-ssd.min.js"></script>
  <style>
    body {
      margin: 0;
      overflow: hidden;
      background: black;
      font-family: Arial, sans-serif;
    }
    #webcam, #canvas {
      position: absolute;
      top: 0;
      left: 0;
      width: 100vw;
      height: 100vh;
      object-fit: cover;
    }
    #status, #clock, #pedestrianWarning {
      position: absolute;
      background: rgba(0, 0, 0, 0.7);
      color: #00ff00;
      padding: 6px 10px;
      font-size: 14px;
      border-radius: 6px;
    }
    #status { top: 10px; left: 10px; }
    #clock { top: 10px; right: 10px; }
    #pedestrianWarning {
      bottom: 10px;
      left: 10px;
      color: yellow;
      font-weight: bold;
      max-width: 80vw;
    }
  </style>
</head>
<body>
  <video id="webcam" autoplay muted playsinline></video>
  <canvas id="canvas"></canvas>
  <div id="status">Loading model...</div>
  <div id="clock">--:--:--</div>
  <div id="pedestrianWarning"></div>  <script>
    let model, webcam, canvas, ctx;
    let lastSpoken = '', lastSpokenTime = 0;
    let pedestrianTimer = null;
    const classes = ['person', 'car', 'truck', 'bus', 'motorcycle', 'bicycle'];

    function speak(text) {
      const now = Date.now();
      if (text !== lastSpoken || now - lastSpokenTime > 5000) {
        const msg = new SpeechSynthesisUtterance(text);
        msg.lang = 'en-US';
        speechSynthesis.speak(msg);
        lastSpoken = text;
        lastSpokenTime = now;
      }
    }

    function updateClock() {
      const now = new Date();
      document.getElementById("clock").innerText = now.toLocaleTimeString();
    }

    async function startCamera() {
      webcam = document.getElementById("webcam");
      canvas = document.getElementById("canvas");
      ctx = canvas.getContext("2d");

      const stream = await navigator.mediaDevices.getUserMedia({
        video: {
          facingMode: { exact: "environment" },
          width: { ideal: 1920 },
          height: { ideal: 1080 }
        }
      });

      webcam.srcObject = stream;

      return new Promise(resolve => {
        webcam.onloadedmetadata = () => {
          canvas.width = webcam.videoWidth;
          canvas.height = webcam.videoHeight;
          resolve();
        };
      });
    }

    function getDirection(x, width) {
      if (x < width / 3) return "on left";
      else if (x > (2 * width) / 3) return "on right";
      return "in front";
    }

    function getProximity(area) {
      if (area > 70000) return "very close";
      if (area > 30000) return "close";
      return "far";
    }

    function alertPedestrianCrossing() {
      const warning = document.getElementById("pedestrianWarning");
      warning.innerText = "⚠️ Pedestrian crossing detected!";
      speak("Caution. Pedestrian crossing ahead");
      if (pedestrianTimer) clearTimeout(pedestrianTimer);
      pedestrianTimer = setTimeout(() => {
        warning.innerText = "";
      }, 5000);
    }

    async function detectFrame() {
      const predictions = await model.detect(webcam);

      ctx.clearRect(0, 0, canvas.width, canvas.height);
      ctx.drawImage(webcam, 0, 0, canvas.width, canvas.height);

      const filtered = predictions.filter(pred => pred.score > 0.6 && classes.includes(pred.class));

      let pedestrianCount = 0;

      filtered.forEach(pred => {
        const [x, y, w, h] = pred.bbox;
        const area = w * h;
        const direction = getDirection(x + w / 2, canvas.width);
        const proximity = getProximity(area);
        const label = `${pred.class} ${proximity} ${direction}`;

        ctx.beginPath();
        ctx.rect(x, y, w, h);
        ctx.lineWidth = 2;
        ctx.strokeStyle = "lime";
        ctx.stroke();
        ctx.fillStyle = "lime";
        ctx.fillText(label, x, y > 10 ? y - 5 : 10);

        if (pred.class === "person") pedestrianCount++;

        if (proximity !== "far") speak(label);
      });

      if (pedestrianCount >= 2) {
        alertPedestrianCrossing();
      }

      requestAnimationFrame(detectFrame);
    }

    async function main() {
      try {
        await startCamera();
        model = await cocoSsd.load();
        document.getElementById("status").innerText = "VisionGuard Ready";
        setInterval(updateClock, 1000);
        detectFrame();
      } catch (err) {
        document.getElementById("status").innerText = "Camera error: " + err.message;
      }
    }

    main();
  </script></body>
</html>
