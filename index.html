<!DOCTYPE html>
<html>
<head>
  <title>VisionGuard - Full Road Safety Assistant</title>

  <!-- Load TensorFlow.js and coco-ssd -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.13.0"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd@2.2.2/dist/coco-ssd.min.js"></script>

  <style>
    body {
      margin: 0;
      background: black;
      overflow: hidden;
      font-family: Arial, sans-serif;
    }
    #webcam, #canvas {
      position: absolute;
      top: 0;
      left: 0;
      width: 100vw;
      height: 100vh;
      object-fit: cover;
      transform: rotate(180deg); /* Fix upside-down view */
    }
    #status {
      position: absolute;
      top: 20px;
      left: 20px;
      background: rgba(0, 0, 0, 0.7);
      color: #00ff00;
      padding: 10px 15px;
      font-size: 18px;
      border-radius: 8px;
    }
  </style>
</head>
<body>
  <video id="webcam" autoplay muted playsinline></video>
  <canvas id="canvas"></canvas>
  <div id="status">Loading model...</div>

  <script>
    let model, webcam, canvas, ctx;
    let spokenRecently = {};

    const speak = (text) => {
      if (!spokenRecently[text]) {
        const msg = new SpeechSynthesisUtterance(text);
        msg.lang = 'en-US';
        speechSynthesis.speak(msg);
        spokenRecently[text] = true;
        setTimeout(() => spokenRecently[text] = false, 4000); // Reset after 4 sec
      }
    };

    async function startCamera() {
      webcam = document.getElementById("webcam");
      canvas = document.getElementById("canvas");
      ctx = canvas.getContext("2d");

      const stream = await navigator.mediaDevices.getUserMedia({
        video: { facingMode: { exact: "environment" } }
      });

      webcam.srcObject = stream;

      return new Promise(resolve => {
        webcam.onloadedmetadata = () => {
          canvas.width = webcam.videoWidth;
          canvas.height = webcam.videoHeight;
          resolve();
        };
      });
    }

    function proximityLabel(objClass, area) {
      if (area > 70000) {
        return `${capitalize(objClass)} very close`;
      } else if (area > 30000) {
        return `${capitalize(objClass)} getting close`;
      } else {
        return `${capitalize(objClass)} far ahead`;
      }
    }

    function capitalize(word) {
      return word.charAt(0).toUpperCase() + word.slice(1);
    }

    async function detectFrame() {
      const predictions = await model.detect(webcam);

      ctx.clearRect(0, 0, canvas.width, canvas.height);
      ctx.drawImage(webcam, 0, 0, canvas.width, canvas.height);

      predictions.forEach(pred => {
        if (pred.score > 0.6) {
          const [x, y, width, height] = pred.bbox;
          const area = width * height;

          ctx.beginPath();
          ctx.rect(x, y, width, height);
          ctx.lineWidth = 2;
          ctx.strokeStyle = "lime";
          ctx.stroke();
          ctx.fillStyle = "lime";
          ctx.fillText(pred.class, x, y > 10 ? y - 5 : 10);

          const allowedClasses = ['car', 'truck', 'motorcycle', 'bus', 'bicycle', 'person'];
          if (allowedClasses.includes(pred.class)) {
            const msg = proximityLabel(pred.class, area);
            speak(msg);
          }
        }
      });

      requestAnimationFrame(detectFrame);
    }

    async function main() {
      try {
        await startCamera();
        model = await cocoSsd.load();
        document.getElementById("status").innerText = "Detecting road objects...";
        detectFrame();
      } catch (err) {
        document.getElementById("status").innerText = "Camera error: " + err.message;
      }
    }

    main();
  </script>
</body>
</html>
